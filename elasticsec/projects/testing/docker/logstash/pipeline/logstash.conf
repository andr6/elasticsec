input {
	tcp {
		type => "syslog_input"
		port => 5000
	}

    file {
        start_position => "beginning"
        path => ["/usr/share/logstash/data/input/bro/*http*"]    
        type => "bro_http"
    }
}


## Add your filters / logstash plugins configuration here

filter {
    if [type] == "syslog_input" {
        dissect {
            mapping => {
                "message" => "%{ts} %{+ts} %{+ts} %{src} %{prog}[%{pid}]: %{msg}"
            }
            add_tag => "syslog"
        }

        date {
            target => "syslog_ts"
            match => ["ts", "MMM dd HH:mm:ss"] 
            remove_field => ["ts"]
        }
    }

    else if [type] == "bro_http" {
        #Let's get rid of those header lines; they begin with a hash
        if [message] =~ /^#/ {
            drop { }
        }
        
        #Now, using the csv filter, we can define the Bro log fields
        csv {
            columns => ["ts","uid","id.orig_h","id.orig_p","id.resp_h","id.resp_p","trans_depth","method","host","uri","referrer","version","user_agent","request_body_len","response_body_len","status_code","status_msg","info_code","info_msg","tags","username","password","proxied","orig_fuids","orig_filenames","orig_mime_types","resp_fuids","resp_filenames","resp_mime_types"]
    
            #If you use a custom delimiter, change the following value in between the quotes to your delimiter. Otherwise, leave the next line alone.
            separator => "	"
        }
    
        #Let's convert our timestamp into the 'ts' field, so we can use Kibana features natively
        date {
            target => "bro_ts"
            match => [ "ts", "UNIX" ]
            remove_field => ["ts"]
        }
    
        mutate {
            convert => [ "id.orig_p", "integer" ]
            convert => [ "id.resp_p", "integer" ]
            convert => [ "trans_depth", "integer" ]
            convert => [ "request_body_len", "integer" ]
            convert => [ "response_body_len", "integer" ]
            convert => [ "status_code", "integer" ]
            convert => [ "info_code", "integer" ]
            rename =>  [ "host", "http_host" ]
            rename =>  [ "id.orig_h", "id_orig_host" ]
            rename =>  [ "id.orig_p", "id_orig_port" ]
            rename =>  [ "id.resp_h", "id_resp_host" ]
            rename =>  [ "id.resp_p", "id_resp_port" ]
            
            add_tag => "bro-http"
        }
    }
}

## Add your filters / logstash plugins configuration here

output {
    if [type] == "syslog_input" {
        elasticsearch {
            hosts => ["elasticsearch:9200"]
			index => "syslog-%{+YYYY.MM.dd}"
		}
	}

    else if "bro" in [type] {
        elasticsearch {
            hosts => ["elasticsearch:9200"]
            index => "bro-%{+YYYY.MM.dd}"
        }
    }
}
